{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"},{"sourceId":13904981,"sourceType":"datasetVersion","datasetId":8762382}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:21.151157Z","iopub.execute_input":"2026-01-05T10:14:21.151874Z","iopub.status.idle":"2026-01-05T10:14:24.331880Z","shell.execute_reply.started":"2026-01-05T10:14:21.151848Z","shell.execute_reply":"2026-01-05T10:14:24.331111Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (2.10.1)\nRequirement already satisfied: alembic in /usr/local/lib/python3.12/dist-packages (from optuna) (1.4.3)\nRequirement already satisfied: cliff in /usr/local/lib/python3.12/dist-packages (from optuna) (4.13.0)\nRequirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (0.12.0)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\nRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.15.3)\nRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.2.19)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic->optuna) (1.3.10)\nRequirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.12/dist-packages (from alembic->optuna) (1.0.4)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from alembic->optuna) (2.9.0.post0)\nRequirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna) (0.5.2)\nRequirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna) (2.7.0)\nRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna) (3.16.0)\nRequirement already satisfied: stevedore>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from cliff->optuna) (5.6.0)\nRequirement already satisfied: pyperclip>=1.8 in /usr/local/lib/python3.12/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.11.0)\nRequirement already satisfied: rich-argparse>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.7.2)\nRequirement already satisfied: wcwidth>=0.2.10 in /usr/local/lib/python3.12/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.14)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic->optuna) (3.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->alembic->optuna) (1.17.0)\nRequirement already satisfied: rich>=11.0.0 in /usr/local/lib/python3.12/dist-packages (from rich-argparse>=1.7.1->cmd2>=1.0.0->cliff->optuna) (14.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.0.0->rich-argparse>=1.7.1->cmd2>=1.0.0->cliff->optuna) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.0.0->rich-argparse>=1.7.1->cmd2>=1.0.0->cliff->optuna) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->rich-argparse>=1.7.1->cmd2>=1.0.0->cliff->optuna) (0.1.2)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# =============================================================================\n# COMPLETE XGBoost + Optuna Tuning Pipeline (GPU Accelerated)\n# Playground Series S6E1 - Exam Score Prediction\n# Includes: Strong Feature Engineering + Hyperparameter Tuning + Final 7-Fold Model\n# =============================================================================\n\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom optuna.pruners import MedianPruner","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:24.333803Z","iopub.execute_input":"2026-01-05T10:14:24.334248Z","iopub.status.idle":"2026-01-05T10:14:24.339186Z","shell.execute_reply.started":"2026-01-05T10:14:24.334194Z","shell.execute_reply":"2026-01-05T10:14:24.338583Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# ----------------------------- Configuration ---------------------------------\nSEED = 42\nnp.random.seed(SEED)\n\nN_FOLDS_TUNE = 5\nN_FOLDS_FINAL = 7\nTARGET = 'exam_score'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:24.340004Z","iopub.execute_input":"2026-01-05T10:14:24.340276Z","iopub.status.idle":"2026-01-05T10:14:24.353455Z","shell.execute_reply.started":"2026-01-05T10:14:24.340241Z","shell.execute_reply":"2026-01-05T10:14:24.352718Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# File paths (Kaggle environment)\nTRAIN_PATH = \"/kaggle/input/playground-series-s6e1/train.csv\"\nTEST_PATH = \"/kaggle/input/playground-series-s6e1/test.csv\"\nORIGINAL_PATH = \"/kaggle/input/exam-score-prediction-dataset/Exam_Score_Prediction.csv\"\nSUBMISSION_PATH = \"/kaggle/input/playground-series-s6e1/sample_submission.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:24.354320Z","iopub.execute_input":"2026-01-05T10:14:24.354534Z","iopub.status.idle":"2026-01-05T10:14:24.366027Z","shell.execute_reply.started":"2026-01-05T10:14:24.354517Z","shell.execute_reply":"2026-01-05T10:14:24.365326Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# ----------------------------- Data Loading ----------------------------------\nprint(\"Loading data...\")\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\noriginal_df = pd.read_csv(ORIGINAL_PATH)\nsubmission_df = pd.read_csv(SUBMISSION_PATH)\n\nbase_features = [col for col in train_df.columns if col not in ['id', TARGET]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:24.367745Z","iopub.execute_input":"2026-01-05T10:14:24.368020Z","iopub.status.idle":"2026-01-05T10:14:25.496592Z","shell.execute_reply.started":"2026-01-05T10:14:24.368001Z","shell.execute_reply":"2026-01-05T10:14:25.495980Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# ----------------------------- Feature Engineering ---------------------------\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n    \n    # Powerful hand-crafted feature\n    df['feature_formula'] = (\n        5.9051154511950499 * df['study_hours'] +\n        0.34540967058057986 * df['class_attendance'] +\n        1.423461171860262 * df['sleep_hours'] + 4.7819\n    )\n    \n    # Polynomial features\n    df['study_hours_squared'] = df['study_hours'] ** 2\n    df['study_hours_cubed'] = df['study_hours'] ** 3\n    df['class_attendance_squared'] = df['class_attendance'] ** 2\n    df['sleep_hours_squared'] = df['sleep_hours'] ** 2\n    df['age_squared'] = df['age'] ** 2\n    \n    # Log and sqrt transformations\n    df['log_study_hours'] = np.log1p(df['study_hours'])\n    df['log_class_attendance'] = np.log1p(df['class_attendance'])\n    df['log_sleep_hours'] = np.log1p(df['sleep_hours'])\n    df['sqrt_study_hours'] = np.sqrt(df['study_hours'])\n    df['sqrt_class_attendance'] = np.sqrt(df['class_attendance'])\n    \n    # Convert original columns to string for XGBoost categorical support\n    for col in base_features:\n        df[col] = df[col].astype(str)\n    \n    engineered_numeric = [\n        'feature_formula', 'study_hours_squared', 'study_hours_cubed',\n        'class_attendance_squared', 'sleep_hours_squared', 'age_squared',\n        'log_study_hours', 'log_class_attendance', 'log_sleep_hours',\n        'sqrt_study_hours', 'sqrt_class_attendance'\n    ]\n    \n    return df[base_features + engineered_numeric]\n\nprint(\"Preprocessing data...\")\nX = preprocess(train_df)\ny = train_df[TARGET].values\n\nX_test = preprocess(test_df)\nX_original = preprocess(original_df)\ny_original = original_df[TARGET].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:25.497632Z","iopub.execute_input":"2026-01-05T10:14:25.498145Z","iopub.status.idle":"2026-01-05T10:14:27.398239Z","shell.execute_reply.started":"2026-01-05T10:14:25.498105Z","shell.execute_reply":"2026-01-05T10:14:27.397644Z"}},"outputs":[{"name":"stdout","text":"Preprocessing data...\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Ensure consistent categorical dtypes\nfull_data = pd.concat([X, X_test, X_original], axis=0)\nfor col in base_features:\n    full_data[col] = full_data[col].astype('category')\n\nengineered_cols = [c for c in full_data.columns if c not in base_features]\nfor col in engineered_cols:\n    full_data[col] = full_data[col].astype(float)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:27.399377Z","iopub.execute_input":"2026-01-05T10:14:27.399700Z","iopub.status.idle":"2026-01-05T10:14:28.074838Z","shell.execute_reply.started":"2026-01-05T10:14:27.399669Z","shell.execute_reply":"2026-01-05T10:14:28.074270Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Split back\nX = full_data.iloc[:len(train_df)].copy()\nX_test = full_data.iloc[len(train_df):len(train_df)+len(test_df)].copy()\nX_original = full_data.iloc[len(train_df)+len(test_df):].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:28.075720Z","iopub.execute_input":"2026-01-05T10:14:28.075950Z","iopub.status.idle":"2026-01-05T10:14:28.204478Z","shell.execute_reply.started":"2026-01-05T10:14:28.075929Z","shell.execute_reply":"2026-01-05T10:14:28.203709Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# ----------------------------- Optuna Objective Function -----------------------------\ndef objective(trial):\n    params = {\n        'n_estimators': 3000,  # Reduced for faster tuning (final model uses 10000)\n        'learning_rate': trial.suggest_float('learning_rate', 0.003, 0.02, log=True),\n        'max_depth': trial.suggest_int('max_depth', 5, 10),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 10.0),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 5.0),\n        'min_child_weight': trial.suggest_float('min_child_weight', 1, 20),\n        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n        \n        'tree_method': 'hist',\n        'device': 'cuda',\n        \n        'random_state': SEED,\n        'eval_metric': 'rmse',\n        'early_stopping_rounds': 150,\n        'enable_categorical': True,\n        'verbosity': 0\n    }\n    \n    kf = KFold(n_splits=N_FOLDS_TUNE, shuffle=True, random_state=SEED)\n    oof_vals = np.zeros(len(X))\n    \n    for train_idx, val_idx in kf.split(X):\n        X_tr = X.iloc[train_idx]\n        y_tr = y[train_idx]\n        X_val = X.iloc[val_idx]\n        y_val = y[val_idx]\n        \n        X_tr_full = pd.concat([X_tr, X_original], axis=0)\n        y_tr_full = np.concatenate([y_tr, y_original])\n        \n        model = xgb.XGBRegressor(**params)\n        model.fit(X_tr_full, y_tr_full, eval_set=[(X_val, y_val)], verbose=False)\n        \n        oof_vals[val_idx] = model.predict(X_val)\n    \n    # FIXED: Compatible with all sklearn versions\n    return np.sqrt(mean_squared_error(y, oof_vals))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:28.205456Z","iopub.execute_input":"2026-01-05T10:14:28.205676Z","iopub.status.idle":"2026-01-05T10:14:28.212817Z","shell.execute_reply.started":"2026-01-05T10:14:28.205657Z","shell.execute_reply":"2026-01-05T10:14:28.212097Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# ----------------------------- Run Optuna Tuning -----------------------------\nprint(\"\\n=== Starting Optuna Tuning ===\")\nsampler = TPESampler(seed=SEED)\npruner = MedianPruner(n_startup_trials=5, n_warmup_steps=5)\nstudy = optuna.create_study(direction='minimize', sampler=sampler, pruner=pruner)\nstudy.optimize(objective, n_trials=20)  \n\nprint(\"\\n=== BEST TRIAL ===\")\nprint(f\"Best OOF RMSE: {study.best_value:.5f}\")\nprint(\"Best parameters:\")\nfor k, v in study.best_params.items():\n    print(f\"  {k}: {v}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T10:14:28.213681Z","iopub.execute_input":"2026-01-05T10:14:28.213894Z","iopub.status.idle":"2026-01-05T12:16:31.977287Z","shell.execute_reply.started":"2026-01-05T10:14:28.213867Z","shell.execute_reply":"2026-01-05T12:16:31.976583Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-05 10:14:28,227]\u001b[0m A new study created in memory with name: no-name-7f2ad01b-f04b-4b1f-ba3c-ff2efb1411c2\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\n=== Starting Optuna Tuning ===\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-05 10:24:17,893]\u001b[0m Trial 0 finished with value: 8.645682578938827 and parameters: {'learning_rate': 0.006105315793640882, 'max_depth': 10, 'subsample': 0.892797576724562, 'colsample_bytree': 0.7993292420985183, 'colsample_bynode': 0.5780093202212182, 'reg_lambda': 2.403950683025824, 'reg_alpha': 0.2904180608409973, 'min_child_weight': 17.457346769723767, 'gamma': 3.005575058716044}. Best is trial 0 with value: 8.645682578938827.\u001b[0m\n\u001b[32m[I 2026-01-05 10:25:20,658]\u001b[0m Trial 1 finished with value: 8.67478165379482 and parameters: {'learning_rate': 0.01149498584437033, 'max_depth': 5, 'subsample': 0.9879639408647978, 'colsample_bytree': 0.9162213204002109, 'colsample_bynode': 0.6061695553391381, 'reg_lambda': 2.636424704863906, 'reg_alpha': 0.9170225492671691, 'min_child_weight': 6.780602616231217, 'gamma': 2.6237821581611893}. Best is trial 0 with value: 8.645682578938827.\u001b[0m\n\u001b[32m[I 2026-01-05 10:28:52,731]\u001b[0m Trial 2 finished with value: 8.642870812411399 and parameters: {'learning_rate': 0.006807764614983674, 'max_depth': 6, 'subsample': 0.8447411578889518, 'colsample_bytree': 0.569746930326021, 'colsample_bynode': 0.6460723242676091, 'reg_lambda': 4.297256589643226, 'reg_alpha': 2.28034992108518, 'min_child_weight': 15.918343266467259, 'gamma': 0.9983689107917987}. Best is trial 2 with value: 8.642870812411399.\u001b[0m\n\u001b[32m[I 2026-01-05 10:32:40,533]\u001b[0m Trial 3 finished with value: 8.639819346397342 and parameters: {'learning_rate': 0.007957992095277986, 'max_depth': 8, 'subsample': 0.6185801650879991, 'colsample_bytree': 0.8037724259507192, 'colsample_bynode': 0.5852620618436457, 'reg_lambda': 1.5854643368675156, 'reg_alpha': 4.7444276862666666, 'min_child_weight': 19.347008628416628, 'gamma': 4.041986740582305}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 10:35:09,407]\u001b[0m Trial 4 finished with value: 8.6597398393137 and parameters: {'learning_rate': 0.005346815541689898, 'max_depth': 5, 'subsample': 0.8736932106048627, 'colsample_bytree': 0.7200762468698007, 'colsample_bynode': 0.5610191174223894, 'reg_lambda': 5.456592191001432, 'reg_alpha': 0.17194260557609198, 'min_child_weight': 18.27708763949686, 'gamma': 1.2938999080000846}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 10:37:25,617]\u001b[0m Trial 5 finished with value: 8.651844293037025 and parameters: {'learning_rate': 0.010543362919010367, 'max_depth': 6, 'subsample': 0.8080272084711243, 'colsample_bytree': 0.7733551396716398, 'colsample_bynode': 0.5924272277627636, 'reg_lambda': 9.726261649881026, 'reg_alpha': 3.8756641168055728, 'min_child_weight': 18.850479889719594, 'gamma': 4.474136752138244}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 10:45:08,389]\u001b[0m Trial 6 finished with value: 8.651764948772929 and parameters: {'learning_rate': 0.009326877515737114, 'max_depth': 10, 'subsample': 0.6353970008207678, 'colsample_bytree': 0.5979914312095727, 'colsample_bynode': 0.522613644455269, 'reg_lambda': 3.927972976869379, 'reg_alpha': 1.9433864484474102, 'min_child_weight': 6.155631603704022, 'gamma': 4.143687545759647}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 10:48:40,978]\u001b[0m Trial 7 finished with value: 8.643694287168403 and parameters: {'learning_rate': 0.0059027370753415576, 'max_depth': 6, 'subsample': 0.8170784332632994, 'colsample_bytree': 0.5704621124873813, 'colsample_bynode': 0.9010984903770198, 'reg_lambda': 1.6709557931179373, 'reg_alpha': 4.9344346830025865, 'min_child_weight': 15.67265061663649, 'gamma': 0.993578407670862}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 11:00:26,656]\u001b[0m Trial 8 finished with value: 8.692888593838642 and parameters: {'learning_rate': 0.003031593556239305, 'max_depth': 9, 'subsample': 0.8827429375390468, 'colsample_bytree': 0.8645035840204937, 'colsample_bynode': 0.8856351733429728, 'reg_lambda': 1.6664018656068134, 'reg_alpha': 1.7923286427213632, 'min_child_weight': 3.2015121309774646, 'gamma': 4.315517129377968}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 11:03:10,225]\u001b[0m Trial 9 finished with value: 8.645949289743688 and parameters: {'learning_rate': 0.00978728037387775, 'max_depth': 6, 'subsample': 0.6254233401144095, 'colsample_bytree': 0.6554911608578311, 'colsample_bynode': 0.6625916610133735, 'reg_lambda': 7.566455605042576, 'reg_alpha': 3.1877873567760657, 'min_child_weight': 17.857042108950203, 'gamma': 2.3610746258097466}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 11:04:51,579]\u001b[0m Trial 10 finished with value: 8.658938567730203 and parameters: {'learning_rate': 0.018023017935829642, 'max_depth': 8, 'subsample': 0.702179550184475, 'colsample_bytree': 0.9661451709558935, 'colsample_bynode': 0.7595720016297405, 'reg_lambda': 7.2122236621223035, 'reg_alpha': 4.865417857436737, 'min_child_weight': 12.398397099438942, 'gamma': 3.289810924855183}. Best is trial 3 with value: 8.639819346397342.\u001b[0m\n\u001b[32m[I 2026-01-05 11:12:55,910]\u001b[0m Trial 11 finished with value: 8.638650655079752 and parameters: {'learning_rate': 0.00419151003863029, 'max_depth': 8, 'subsample': 0.7424364893339974, 'colsample_bytree': 0.512141581748615, 'colsample_bynode': 0.7171781358782056, 'reg_lambda': 4.301600071004415, 'reg_alpha': 3.0976697156679953, 'min_child_weight': 13.841288416331665, 'gamma': 0.12418376001879206}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 11:21:30,222]\u001b[0m Trial 12 finished with value: 8.63902782311464 and parameters: {'learning_rate': 0.00396281088934536, 'max_depth': 8, 'subsample': 0.7218880653248096, 'colsample_bytree': 0.506348191569923, 'colsample_bynode': 0.7566297445510355, 'reg_lambda': 3.9786937938775906, 'reg_alpha': 3.7958047797522942, 'min_child_weight': 12.349449304006711, 'gamma': 0.029170201041014504}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 11:26:57,374]\u001b[0m Trial 13 finished with value: 8.639997900743655 and parameters: {'learning_rate': 0.003703950978026483, 'max_depth': 7, 'subsample': 0.7330627311119459, 'colsample_bytree': 0.5009396876597588, 'colsample_bynode': 0.7674530668901639, 'reg_lambda': 4.088844561825624, 'reg_alpha': 3.317032143059912, 'min_child_weight': 11.955489521451979, 'gamma': 0.09222986829757768}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 11:38:37,181]\u001b[0m Trial 14 finished with value: 8.644390872595373 and parameters: {'learning_rate': 0.004284659488711341, 'max_depth': 9, 'subsample': 0.7010764346678157, 'colsample_bytree': 0.5008533723028714, 'colsample_bynode': 0.8155421717694824, 'reg_lambda': 5.828764381673284, 'reg_alpha': 3.928380493827913, 'min_child_weight': 9.412059661326538, 'gamma': 0.22737489173284106}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 11:45:38,542]\u001b[0m Trial 15 finished with value: 8.641673732794349 and parameters: {'learning_rate': 0.004124066149085606, 'max_depth': 8, 'subsample': 0.751961674665263, 'colsample_bytree': 0.6869888528707921, 'colsample_bynode': 0.6954682599646516, 'reg_lambda': 5.997733448120759, 'reg_alpha': 2.907757803289703, 'min_child_weight': 13.740357709492839, 'gamma': 1.5879324891632103}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 11:51:08,051]\u001b[0m Trial 16 finished with value: 8.64343029694895 and parameters: {'learning_rate': 0.0030270993912187116, 'max_depth': 7, 'subsample': 0.7454563758532478, 'colsample_bytree': 0.6393315974975737, 'colsample_bynode': 0.830299622914229, 'reg_lambda': 3.3237215312678656, 'reg_alpha': 3.965829038201079, 'min_child_weight': 10.2905922614235, 'gamma': 0.4678172524398644}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 12:01:10,748]\u001b[0m Trial 17 finished with value: 8.640333274870759 and parameters: {'learning_rate': 0.00489958083766331, 'max_depth': 9, 'subsample': 0.6888222478751507, 'colsample_bytree': 0.5544200504307555, 'colsample_bynode': 0.7056837964307551, 'reg_lambda': 4.92489850215052, 'reg_alpha': 2.6574962928081236, 'min_child_weight': 13.974858528867005, 'gamma': 0.6351164148798749}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 12:03:16,022]\u001b[0m Trial 18 finished with value: 8.644647521554427 and parameters: {'learning_rate': 0.01518227705711354, 'max_depth': 7, 'subsample': 0.7736334986900498, 'colsample_bytree': 0.5001951204548482, 'colsample_bynode': 0.8224413566586759, 'reg_lambda': 6.904394509793828, 'reg_alpha': 3.627714831811071, 'min_child_weight': 6.761577915371014, 'gamma': 1.99647324159403}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n\u001b[32m[I 2026-01-05 12:16:31,973]\u001b[0m Trial 19 finished with value: 8.648063956571363 and parameters: {'learning_rate': 0.00370342266034569, 'max_depth': 9, 'subsample': 0.6654339226307291, 'colsample_bytree': 0.6257610324984326, 'colsample_bynode': 0.952162903789609, 'reg_lambda': 8.851603125580088, 'reg_alpha': 4.360716544683662, 'min_child_weight': 8.944927563359405, 'gamma': 1.726152551174813}. Best is trial 11 with value: 8.638650655079752.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\n=== BEST TRIAL ===\nBest OOF RMSE: 8.63865\nBest parameters:\n  learning_rate: 0.00419151003863029\n  max_depth: 8\n  subsample: 0.7424364893339974\n  colsample_bytree: 0.512141581748615\n  colsample_bynode: 0.7171781358782056\n  reg_lambda: 4.301600071004415\n  reg_alpha: 3.0976697156679953\n  min_child_weight: 13.841288416331665\n  gamma: 0.12418376001879206\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ----------------------------- Train Final Model with Best Params -----------------------------\nbest_params = {\n    'n_estimators': 10000,                    \n    'early_stopping_rounds': 150,\n    'eval_metric': 'rmse',\n    'tree_method': 'hist',\n    'device': 'cuda',                         \n    'enable_categorical': True,\n    'random_state': SEED,\n    'verbosity': 0\n}\nbest_params.update(study.best_params)         \n\nprint(f\"\\n=== Training Final {N_FOLDS_FINAL}-Fold Model with Tuned Parameters ===\")\nprint(\"Best parameters used:\")\nfor k, v in best_params.items():\n    if k in study.best_params:                \n        print(f\"   {k}: {v}  ‚Üê tuned\")\n    else:\n        print(f\"   {k}: {v}\")\n\nkf = KFold(n_splits=N_FOLDS_FINAL, shuffle=True, random_state=SEED)\noof_predictions = np.zeros(len(X))\ntest_predictions = np.zeros(len(X_test))\nfold_rmses = []\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\n--- Fold {fold + 1}/{N_FOLDS_FINAL} ---\")\n    \n    X_train = X.iloc[train_idx]\n    y_train = y[train_idx]\n    X_val = X.iloc[val_idx]\n    y_val = y[val_idx]\n    \n    # Combine with original data for training\n    X_train_full = pd.concat([X_train, X_original], axis=0)\n    y_train_full = np.concatenate([y_train, y_original])\n    \n    model = xgb.XGBRegressor(**best_params)\n    model.fit(\n        X_train_full, y_train_full,\n        eval_set=[(X_val, y_val)],\n        verbose=1000\n    )\n    \n    # Predictions\n    val_pred = model.predict(X_val)\n    oof_predictions[val_idx] = val_pred\n    \n    # FIXED RMSE calculation (compatible with all sklearn versions)\n    fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n    fold_rmses.append(fold_rmse)\n    print(f\"Fold {fold + 1} RMSE: {fold_rmse:.5f}\")\n    \n    # Accumulate test predictions\n    test_predictions += model.predict(X_test) / N_FOLDS_FINAL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-05T12:16:31.978241Z","iopub.execute_input":"2026-01-05T12:16:31.978452Z","iopub.status.idle":"2026-01-05T12:28:46.851453Z","shell.execute_reply.started":"2026-01-05T12:16:31.978432Z","shell.execute_reply":"2026-01-05T12:28:46.850845Z"}},"outputs":[{"name":"stdout","text":"\n=== Training Final 7-Fold Model with Tuned Parameters ===\nBest parameters used:\n   n_estimators: 10000\n   early_stopping_rounds: 150\n   eval_metric: rmse\n   tree_method: hist\n   device: cuda\n   enable_categorical: True\n   random_state: 42\n   verbosity: 0\n   learning_rate: 0.00419151003863029  ‚Üê tuned\n   max_depth: 8  ‚Üê tuned\n   subsample: 0.7424364893339974  ‚Üê tuned\n   colsample_bytree: 0.512141581748615  ‚Üê tuned\n   colsample_bynode: 0.7171781358782056  ‚Üê tuned\n   reg_lambda: 4.301600071004415  ‚Üê tuned\n   reg_alpha: 3.0976697156679953  ‚Üê tuned\n   min_child_weight: 13.841288416331665  ‚Üê tuned\n   gamma: 0.12418376001879206  ‚Üê tuned\n\n--- Fold 1/7 ---\n[0]\tvalidation_0-rmse:18.79980\n[1000]\tvalidation_0-rmse:8.65891\n[2000]\tvalidation_0-rmse:8.60402\n[2705]\tvalidation_0-rmse:8.60285\nFold 1 RMSE: 8.60274\n\n--- Fold 2/7 ---\n[0]\tvalidation_0-rmse:18.86033\n[1000]\tvalidation_0-rmse:8.70398\n[2000]\tvalidation_0-rmse:8.64449\n[3000]\tvalidation_0-rmse:8.64218\n[3040]\tvalidation_0-rmse:8.64225\nFold 2 RMSE: 8.64211\n\n--- Fold 3/7 ---\n[0]\tvalidation_0-rmse:18.84363\n[1000]\tvalidation_0-rmse:8.70124\n[2000]\tvalidation_0-rmse:8.64373\n[3000]\tvalidation_0-rmse:8.64164\n[3256]\tvalidation_0-rmse:8.64184\nFold 3 RMSE: 8.64158\n\n--- Fold 4/7 ---\n[0]\tvalidation_0-rmse:18.83460\n[1000]\tvalidation_0-rmse:8.68110\n[2000]\tvalidation_0-rmse:8.62392\n[3000]\tvalidation_0-rmse:8.62216\n[3100]\tvalidation_0-rmse:8.62234\nFold 4 RMSE: 8.62212\n\n--- Fold 5/7 ---\n[0]\tvalidation_0-rmse:18.95760\n[1000]\tvalidation_0-rmse:8.71816\n[2000]\tvalidation_0-rmse:8.65769\n[3000]\tvalidation_0-rmse:8.65610\n[3127]\tvalidation_0-rmse:8.65621\nFold 5 RMSE: 8.65597\n\n--- Fold 6/7 ---\n[0]\tvalidation_0-rmse:18.85901\n[1000]\tvalidation_0-rmse:8.66879\n[2000]\tvalidation_0-rmse:8.61613\n[2785]\tvalidation_0-rmse:8.61448\nFold 6 RMSE: 8.61430\n\n--- Fold 7/7 ---\n[0]\tvalidation_0-rmse:18.92657\n[1000]\tvalidation_0-rmse:8.72945\n[2000]\tvalidation_0-rmse:8.66500\n[2811]\tvalidation_0-rmse:8.66229\nFold 7 RMSE: 8.66215\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# ----------------------------- Final Results ---------------------------------------\noof_rmse = np.sqrt(mean_squared_error(y, oof_predictions))\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"FINAL TUNED OOF RMSE: {oof_rmse:.5f}\")\nprint(f\"Mean Fold RMSE: {np.mean(fold_rmses):.5f} ¬± {np.std(fold_rmses):.5f}\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T12:28:46.852381Z","iopub.execute_input":"2026-01-05T12:28:46.852582Z","iopub.status.idle":"2026-01-05T12:28:46.861107Z","shell.execute_reply.started":"2026-01-05T12:28:46.852564Z","shell.execute_reply":"2026-01-05T12:28:46.860528Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nFINAL TUNED OOF RMSE: 8.63445\nMean Fold RMSE: 8.63442 ¬± 0.02037\n============================================================\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Save OOF and submission\noof_df = pd.DataFrame({'id': train_df['id'], TARGET: oof_predictions})\noof_df.to_csv('xgb_tuned_oof.csv', index=False)\n\nsubmission_df[TARGET] = np.clip(test_predictions, 0, 100)\nsubmission_df.to_csv('submission_xgb_tuned.csv', index=False)\n\nprint(\"\\nSubmission head:\")\nprint(submission_df.head())\n\nprint(\"\\nFiles saved:\")\nprint(\"  - xgb_tuned_oof.csv\")\nprint(\"  - submission_xgb_tuned.csv\")\nprint(\"\\nSubmit 'submission_xgb_tuned.csv' to the leaderboard for your improved score! üöÄ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T12:28:46.862013Z","iopub.execute_input":"2026-01-05T12:28:46.862359Z","iopub.status.idle":"2026-01-05T12:28:48.436548Z","shell.execute_reply.started":"2026-01-05T12:28:46.862319Z","shell.execute_reply":"2026-01-05T12:28:48.435835Z"}},"outputs":[{"name":"stdout","text":"\nSubmission head:\n       id  exam_score\n0  630000   68.926657\n1  630001   70.045183\n2  630002   90.467629\n3  630003   56.486891\n4  630004   45.580549\n\nFiles saved:\n  - xgb_tuned_oof.csv\n  - submission_xgb_tuned.csv\n\nSubmit 'submission_xgb_tuned.csv' to the leaderboard for your improved score! üöÄ\n","output_type":"stream"}],"execution_count":33}]}