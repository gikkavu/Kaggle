{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"},{"sourceId":13904981,"sourceType":"datasetVersion","datasetId":8762382},{"sourceId":14415296,"sourceType":"datasetVersion","datasetId":9193742}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T22:16:56.770499Z","iopub.execute_input":"2026-01-06T22:16:56.770789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q hillclimbers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport hashlib\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom hillclimbers import climb_hill, partial\n\n# ==========================================\n# 0. CONFIGURATION\n# ==========================================\ntest_req = False       # Set to True for fast execution, False for final submission\nskip_hillclimb = False  \nPATH = \"/kaggle/input/s6e1-models/\" \nTARGET = 'exam_score'\n\n# ==========================================\n# 1. SETUP & DATA LOADING\n# ==========================================\nprint(f\"--- Initializing Data Loading (Mode: {'TEST' if test_req else 'FULL'}) ---\")\noof_files = sorted(glob.glob(os.path.join(PATH, \"**/*_oof.csv\"), recursive=True))\nif not oof_files:\n    oof_files = sorted(glob.glob(\"/kaggle/input/**/*_oof.csv\", recursive=True))\n\nsub_files = [f.replace(\"_oof.csv\", \"_sub.csv\") for f in oof_files]\nmodel_names = [os.path.basename(f).replace(\"_oof.csv\", \"\") for f in oof_files]\n\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/train.csv\")\ny_true = train_df[TARGET].values \n\n# --- Phase 0: Deduplication ---\nunique_subs = {}\nindices_to_keep = []\n\nfor i, (s_file, name) in enumerate(zip(sub_files, model_names)):\n    temp_sub = pd.read_csv(s_file)[TARGET].values\n    sub_hash = hashlib.md5(temp_sub.tobytes()).hexdigest()\n    if sub_hash not in unique_subs:\n        unique_subs[sub_hash] = name\n        indices_to_keep.append(i)\n    else:\n        print(f\"‚ö†Ô∏è Dropping duplicate: {name}\")\n\noof_files = [oof_files[i] for i in indices_to_keep]\nsub_files = [sub_files[i] for i in indices_to_keep]\nmodel_names = [model_names[i] for i in indices_to_keep]\n\noofs = np.stack([pd.read_csv(f)[TARGET].values for f in oof_files], axis=1)\nsubs = np.stack([pd.read_csv(f)[TARGET].values for f in sub_files], axis=1)\n\nprint(f\"‚úÖ Data loaded. Models: {len(model_names)}\")\n\n# ==========================================\n# 2. PHASE 1: HILL CLIMBING\n# ==========================================\ndf_oof_indexed = pd.DataFrame(oofs, columns=model_names)\ndf_sub_indexed = pd.DataFrame(subs, columns=model_names)\n\nhc_precision = 0.01 if test_req else 0.001\nhc_negative = False if test_req else True\n\nif test_req:\n    np.random.seed(42)\n    sample_idx = np.random.choice(len(train_df), size=int(len(train_df)*0.2), replace=False)\n    hc_train_subset = train_df.iloc[sample_idx].reset_index(drop=True)\n    hc_oof_subset = df_oof_indexed.iloc[sample_idx].reset_index(drop=True)\n    print(f\"üìâ Test Mode: Downsampled HC to {len(hc_train_subset)} rows.\")\nelse:\n    hc_train_subset = train_df\n    hc_oof_subset = df_oof_indexed\n\nif not skip_hillclimb:\n    print(f\"\\nüöÄ Initiating Hill Climbing (Precision: {hc_precision}, Neg Weights: {hc_negative})\")\n    \n    # HC returns numpy arrays when return_oof_preds=True\n    hc_test, hc_oof = climb_hill(\n        train=hc_train_subset, \n        target=TARGET, \n        objective='minimize', \n        eval_metric=partial(root_mean_squared_error),\n        oof_pred_df=hc_oof_subset, \n        test_pred_df=df_sub_indexed,\n        plot_hill=True,\n        plot_hist=False, \n        precision=hc_precision,\n        negative_weights=hc_negative,\n        return_oof_preds=True\n    )\n    \n    # Handle the AttributeError by treating the blended output as a single feature for RidgeCV\n    # Note: If test_req is True, hc_oof is only the length of the sample. \n    # To keep stacking consistent on the FULL dataset, we use the HC result as the new input.\n    if test_req:\n        print(\"‚ö†Ô∏è Note: Using library output for Phase 2 (Sampled OOF).\")\n        X_train_hc = hc_oof.reshape(-1, 1)\n        y_true_stacking = hc_train_subset[TARGET].values\n    else:\n        X_train_hc = hc_oof.reshape(-1, 1)\n        y_true_stacking = y_true\n        \n    X_test_hc = hc_test.reshape(-1, 1)\n    selected_model_names = ['HC_Blended_Feature']\nelse:\n    print(\"\\n‚ö†Ô∏è Skipping Hill Climbing.\")\n    X_train_hc = oofs\n    y_true_stacking = y_true\n    X_test_hc = subs\n    selected_model_names = model_names\n\n# ==========================================\n# 3. PHASE 2: RIDGE CV (STACKING)\n# ==========================================\nprint(f\"\\n--- Phase 2: Training RidgeCV Meta-Model ---\")\nkf_splits = 3 if test_req else 10 \nkf = KFold(n_splits=kf_splits, shuffle=True, random_state=42)\nalphas = np.logspace(-2, 4, 15) if test_req else np.logspace(-2, 7, 50)\n\noof_final_preds = np.zeros(len(y_true_stacking))\nsub_final_preds = np.zeros(X_test_hc.shape[0]) \n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train_hc)):\n    X_tr, y_tr = X_train_hc[train_idx], y_true_stacking[train_idx]\n    X_va, y_va = X_train_hc[val_idx], y_true_stacking[val_idx]\n    \n    model = RidgeCV(alphas=alphas, scoring='neg_root_mean_squared_error')\n    model.fit(X_tr, y_tr)\n    \n    oof_final_preds[val_idx] = model.predict(X_va)\n    sub_final_preds += model.predict(X_test_hc) / kf_splits\n    print(f\"Fold {fold+1}/{kf_splits} complete. Alpha: {model.alpha_:.2f}\")\n\n# ==========================================\n# 4. FINAL PERFORMANCE & EXPORT\n# ==========================================\nfinal_rmse = root_mean_squared_error(y_true_stacking, oof_final_preds)\nprint(f\"\\n\" + \"=\"*35)\nprint(f\"‚úÖ FINAL ENSEMBLE RMSE: {final_rmse:.6f}\")\nprint(\"=\"*35)\n\nfinal_sub_preds = np.clip(sub_final_preds, train_df[TARGET].min(), train_df[TARGET].max())\nsub_template = pd.read_csv(\"/kaggle/input/playground-series-s6e1/sample_submission.csv\")\nsub_template[TARGET] = final_sub_preds\nsub_file = f\"submission_rmse_{final_rmse:.6f}.csv\"\nsub_template.to_csv(sub_file, index=False)\n\nprint(f\"üöÄ Saved to: {sub_file}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}