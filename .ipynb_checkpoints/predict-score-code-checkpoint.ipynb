{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-06T22:16:56.770789Z",
     "iopub.status.busy": "2026-01-06T22:16:56.770499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'hillclimbers' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'hillclimbers'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q hillclimbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Data Loading (Mode: FULL) ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m sub_files \u001b[38;5;241m=\u001b[39m [sub_files[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices_to_keep]\n\u001b[1;32m     50\u001b[0m model_names \u001b[38;5;241m=\u001b[39m [model_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices_to_keep]\n\u001b[0;32m---> 52\u001b[0m oofs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([pd\u001b[38;5;241m.\u001b[39mread_csv(f)[TARGET]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m oof_files], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m subs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([pd\u001b[38;5;241m.\u001b[39mread_csv(f)[TARGET]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m sub_files], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Data loaded. Models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(model_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/numpy/_core/shape_base.py:453\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    451\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    455\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from hillclimbers import climb_hill, partial\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURATION\n",
    "# ==========================================\n",
    "test_req = False       # Set to True for fast execution, False for final submission\n",
    "skip_hillclimb = False  \n",
    "PATH = \"/kaggle/input/s6e1-models/\" \n",
    "TARGET = 'exam_score'\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & DATA LOADING\n",
    "# ==========================================\n",
    "print(f\"--- Initializing Data Loading (Mode: {'TEST' if test_req else 'FULL'}) ---\")\n",
    "oof_files = sorted(glob.glob(os.path.join(PATH, \"**/*_oof.csv\"), recursive=True))\n",
    "if not oof_files:\n",
    "    oof_files = sorted(glob.glob(\"/kaggle/input/**/*_oof.csv\", recursive=True))\n",
    "\n",
    "sub_files = [f.replace(\"_oof.csv\", \"_sub.csv\") for f in oof_files]\n",
    "model_names = [os.path.basename(f).replace(\"_oof.csv\", \"\") for f in oof_files]\n",
    "\n",
    "train_df = pd.read_csv(\"/Users/kavuk/Desktop/GitHub/Kaggle/KaggleData/playground-series-s6e1/train.csv\")\n",
    "y_true = train_df[TARGET].values \n",
    "\n",
    "# --- Phase 0: Deduplication ---\n",
    "unique_subs = {}\n",
    "indices_to_keep = []\n",
    "\n",
    "for i, (s_file, name) in enumerate(zip(sub_files, model_names)):\n",
    "    temp_sub = pd.read_csv(s_file)[TARGET].values\n",
    "    sub_hash = hashlib.md5(temp_sub.tobytes()).hexdigest()\n",
    "    if sub_hash not in unique_subs:\n",
    "        unique_subs[sub_hash] = name\n",
    "        indices_to_keep.append(i)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Dropping duplicate: {name}\")\n",
    "\n",
    "oof_files = [oof_files[i] for i in indices_to_keep]\n",
    "sub_files = [sub_files[i] for i in indices_to_keep]\n",
    "model_names = [model_names[i] for i in indices_to_keep]\n",
    "\n",
    "oofs = np.stack([pd.read_csv(f)[TARGET].values for f in oof_files], axis=1)\n",
    "subs = np.stack([pd.read_csv(f)[TARGET].values for f in sub_files], axis=1)\n",
    "\n",
    "print(f\"‚úÖ Data loaded. Models: {len(model_names)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. PHASE 1: HILL CLIMBING\n",
    "# ==========================================\n",
    "df_oof_indexed = pd.DataFrame(oofs, columns=model_names)\n",
    "df_sub_indexed = pd.DataFrame(subs, columns=model_names)\n",
    "\n",
    "hc_precision = 0.01 if test_req else 0.001\n",
    "hc_negative = False if test_req else True\n",
    "\n",
    "if test_req:\n",
    "    np.random.seed(42)\n",
    "    sample_idx = np.random.choice(len(train_df), size=int(len(train_df)*0.2), replace=False)\n",
    "    hc_train_subset = train_df.iloc[sample_idx].reset_index(drop=True)\n",
    "    hc_oof_subset = df_oof_indexed.iloc[sample_idx].reset_index(drop=True)\n",
    "    print(f\"üìâ Test Mode: Downsampled HC to {len(hc_train_subset)} rows.\")\n",
    "else:\n",
    "    hc_train_subset = train_df\n",
    "    hc_oof_subset = df_oof_indexed\n",
    "\n",
    "if not skip_hillclimb:\n",
    "    print(f\"\\nüöÄ Initiating Hill Climbing (Precision: {hc_precision}, Neg Weights: {hc_negative})\")\n",
    "    \n",
    "    # HC returns numpy arrays when return_oof_preds=True\n",
    "    hc_test, hc_oof = climb_hill(\n",
    "        train=hc_train_subset, \n",
    "        target=TARGET, \n",
    "        objective='minimize', \n",
    "        eval_metric=partial(root_mean_squared_error),\n",
    "        oof_pred_df=hc_oof_subset, \n",
    "        test_pred_df=df_sub_indexed,\n",
    "        plot_hill=True,\n",
    "        plot_hist=False, \n",
    "        precision=hc_precision,\n",
    "        negative_weights=hc_negative,\n",
    "        return_oof_preds=True\n",
    "    )\n",
    "    \n",
    "    # Handle the AttributeError by treating the blended output as a single feature for RidgeCV\n",
    "    # Note: If test_req is True, hc_oof is only the length of the sample. \n",
    "    # To keep stacking consistent on the FULL dataset, we use the HC result as the new input.\n",
    "    if test_req:\n",
    "        print(\"‚ö†Ô∏è Note: Using library output for Phase 2 (Sampled OOF).\")\n",
    "        X_train_hc = hc_oof.reshape(-1, 1)\n",
    "        y_true_stacking = hc_train_subset[TARGET].values\n",
    "    else:\n",
    "        X_train_hc = hc_oof.reshape(-1, 1)\n",
    "        y_true_stacking = y_true\n",
    "        \n",
    "    X_test_hc = hc_test.reshape(-1, 1)\n",
    "    selected_model_names = ['HC_Blended_Feature']\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Skipping Hill Climbing.\")\n",
    "    X_train_hc = oofs\n",
    "    y_true_stacking = y_true\n",
    "    X_test_hc = subs\n",
    "    selected_model_names = model_names\n",
    "\n",
    "# ==========================================\n",
    "# 3. PHASE 2: RIDGE CV (STACKING)\n",
    "# ==========================================\n",
    "print(f\"\\n--- Phase 2: Training RidgeCV Meta-Model ---\")\n",
    "kf_splits = 3 if test_req else 10 \n",
    "kf = KFold(n_splits=kf_splits, shuffle=True, random_state=42)\n",
    "alphas = np.logspace(-2, 4, 15) if test_req else np.logspace(-2, 7, 50)\n",
    "\n",
    "oof_final_preds = np.zeros(len(y_true_stacking))\n",
    "sub_final_preds = np.zeros(X_test_hc.shape[0]) \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_hc)):\n",
    "    X_tr, y_tr = X_train_hc[train_idx], y_true_stacking[train_idx]\n",
    "    X_va, y_va = X_train_hc[val_idx], y_true_stacking[val_idx]\n",
    "    \n",
    "    model = RidgeCV(alphas=alphas, scoring='neg_root_mean_squared_error')\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    oof_final_preds[val_idx] = model.predict(X_va)\n",
    "    sub_final_preds += model.predict(X_test_hc) / kf_splits\n",
    "    print(f\"Fold {fold+1}/{kf_splits} complete. Alpha: {model.alpha_:.2f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. FINAL PERFORMANCE & EXPORT\n",
    "# ==========================================\n",
    "final_rmse = root_mean_squared_error(y_true_stacking, oof_final_preds)\n",
    "print(f\"\\n\" + \"=\"*35)\n",
    "print(f\"‚úÖ FINAL ENSEMBLE RMSE: {final_rmse:.6f}\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "final_sub_preds = np.clip(sub_final_preds, train_df[TARGET].min(), train_df[TARGET].max())\n",
    "sub_template = pd.read_csv(\"/kaggle/input/playground-series-s6e1/sample_submission.csv\")\n",
    "sub_template[TARGET] = final_sub_preds\n",
    "sub_file = f\"submission_rmse_{final_rmse:.6f}.csv\"\n",
    "sub_template.to_csv(sub_file, index=False)\n",
    "\n",
    "print(f\"üöÄ Saved to: {sub_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14993753,
     "sourceId": 119082,
     "sourceType": "competition"
    },
    {
     "datasetId": 8762382,
     "sourceId": 13904981,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9193742,
     "sourceId": 14415296,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
